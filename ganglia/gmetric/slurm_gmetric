#!/usr/bin/python
# Rune M. Friborg (2015)
# Version: 1.4
#
# This software has been tested with Slurm 15.08.4
#
# This will submit a large amount of metric data every minute.
# slurm-gmetric will forcefully kill any already running versions of this software



# Host to run this script (protects against multiple daemons)
EXECHOST='s02n67.genomedk.net'

# Slurm
SLURM_BIN_PREFIX = '/opt/slurm/bin/'

# Ganglia settings
GMETRIC  = '/com/extra/ganglia/3.6.0/bin/gmetric'
GMOND_CFG = '/com/extra/ganglia/3.6.0/etc/gmond.conf'

# DEBUG / Testing (Do not send metric data)
DEBUG     = False

# Run once, then quit
ONESHOT   = False

# Run as daemon
DAEMONIZE = True


import subprocess
import os, sys
import time
import signal
from string import join

# Check host
import socket
if EXECHOST != socket.gethostname():
    sys.stderr.write("Error! slurm_gmetric must run from " + EXECHOST) 
    sys.exit(1)

# BINARY PATHS
SDIAG  =   SLURM_BIN_PREFIX + 'sdiag'
SQUEUE =   SLURM_BIN_PREFIX + 'squeue'
SINFO  =   SLURM_BIN_PREFIX + 'sinfo'
SACCTMGR = SLURM_BIN_PREFIX + 'sacctmgr'

SQUEUE_ARGS = ["-h", "--array", "-o", "%A %u %t %V %P %C %E"]
SACCTMGR_USER_CMD = [SACCTMGR, "-nP", "show", "users"]

def transmit_data(name, val, typ, units, title):
    if not DEBUG:
        try:
            os.spawnl(os.P_WAIT, GMETRIC, 'gmetric',
                      '-c'+GMOND_CFG,
                      '--name='  + name,   # E.g bytes_out
                      '--value=' + str(val), # E.g an int value
                      '--type='  + typ,    # E.g uint32
                      '--units=' + units,  # E.g bytes/sec
                      '--group=slurm',     # E.g network
                      '--title=' + title,
                      '--desc='  + "fisk")  # E.g "Network bytes sent/sec"
        except OSError:
            sys.stderr.write("transmit_data failed with an OSError\n")
            pass

    else:
        print join([GMETRIC, 'gmetric',
                  '-c'+GMOND_CFG,
                  '--name='  + name,   # E.g bytes_out
                  '--value=' + str(val),    # E.g an int value
                  '--type='  + typ,    # E.g uint32
                  '--units=' + units,  # E.g bytes/sec
                  '--group=slurm',     # E.g network
                  '--title=' + title])  # E.g "Network bytes sent/sec"

# Parses the time used by sdiag.
def parse_sdiag_time(inp):
    res = time.strptime(join(inp), "%b %d %H:%M:%S %Y")
    return res

# Cmd execution
class ReadCmdException(Exception):
    pass

def readcmd(cmdlist):
    try:
        proc = subprocess.Popen(cmdlist,stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
    except IOError:
        sys.stderr.write("readcmd failed with an IOError\n")
        sys.stderr.write("readcmd: " + str(cmdlist) + "\n")
        raise ReadCmdException(str(cmdlist))


    if proc.returncode != 0:
        sys.stderr.write("readcmd failed with returncode: " + str(proc.returncode) + "\n")
        sys.stderr.write("readcmd: " + str(cmdlist) + "\n")
	raise ReadCmdException(str(cmdlist))

    data = stdout.strip().split("\n")
    return data

# Execute commands to gather squeue data and parse it
def gather_squeue_data():
    try:
        v = readcmd([SQUEUE] + SQUEUE_ARGS)
    except ReadCmdException:
        # Try again next time.
        return None

    running_list = []
    hold_list = []
    pending_list = []

    #SQUEUE_ARGS = ["-h", "--array", "-o", "%A %u %t %V %P %C %E"]
    for l in v:
        job = l.split(' ')
        if len(job) == 6:
            jobid, user, status, submittime, partition, cpus = job
            dependency = ""
        else:
            jobid, user, status, submittime, partition, cpus, dependency = job
        

        if status == "R":
            running_list.append(job[:6])
        elif status == "PD":   
            if dependency == "":
                pending_list.append(job[:6])
            else:
                hold_list.append(job)

    data = {
        "running": running_list,
        "hold" : hold_list,
        "pending": pending_list
        }

    return data

# MEASUREMENT: Measures cores used per user.
def cores_per_user(data):
    try:
        userlist = readcmd(SACCTMGR_USER_CMD)
    except ReadCmdException:
        # Try again next time.
        return

    users = {}

    for line in userlist:
        user = line.split("|")[0]
        users[user] = 0

    for job in data["running"]:
        user = job[1]
        ncpu = int(job[5])

        users[user] += ncpu

    for key in users.keys():
        transmit_data("slurm_cores_" + key,
                users[key],
                "uint32",
                "cores",
                "Cores used for user " + key)


# MEASUREMENT: Waiting time per queue.
def waiting_time(data):

    now = time.time()

    maxwait = {
        "express": float(2**31-1),
        "normal":  float(2**31-1),
        "fat1":    float(2**31-1),
        "fat2":    float(2**31-1),
        "ipsych_express": float(2**31-1),
        "ipsych_normal":  float(2**31-1),
        "ipsych_fat1":    float(2**31-1),
        "ipsych_fat2":    float(2**31-1),
    }


    for job in data["pending"]:
        jobid, user, status, submittime, partition, cpus = job

        t = time.mktime(time.strptime(submittime, "%Y-%m-%dT%H:%M:%S"))

        partition_list = partition.split(",")
        for p in partition_list:
            if p in maxwait:
                if maxwait[p] > t:
                    maxwait[p] = t
            else:
                sys.stderr.write("Error parsing partition list:'"+str(partition_list)+"'\n")

    for k in maxwait.keys():
        if maxwait[k] == 2**31-1:
            maxwait[k] = 0
        else:
            maxwait[k] = (now - maxwait[k])/(60*60)

        transmit_data("slurm_hours_maxwait_" + k,
                maxwait[k],
                "float",
                "hours",
                "Waiting time in hours for pending jobs in queue " + k
            )


# MEASUREMENT: List of active jobs on cluster
def active_jobs(data):
    running = len(data["running"])
    pending = len(data["pending"])
    hold    = len(data["hold"])

    count_distinct_r_users = 0
    count_distinct_p_users = 0
    count_distinct_h_users = 0

    users = zip(*data["running"])
    if users:  
        count_distinct_r_users = len(set(users[1]))

    users = zip(*data["pending"])
    if users:  
        count_distinct_p_users = len(set(users[1]))

    users = zip(*data["hold"])
    if users:  
        count_distinct_h_users = len(set(users[1]))


    transmit_data("slurm_jobs_running",
            running,
            "uint32",
            "jobs",
            "Amount of jobs currently running on cluster")

    transmit_data("slurm_jobs_pending",
            pending,
            "uint32",
            "jobs",
            "Amount of jobs currently pending on cluster")

    transmit_data("slurm_jobs_onhold",
            hold,
            "uint32",
            "jobs",
            "Amount of jobs waiting for prerequisite jobs to finish")

    transmit_data("slurm_users_running",
            count_distinct_r_users,
            "uint32",
            "users",
            "Users with running jobs on cluster")

    transmit_data("slurm_users_pending",
            count_distinct_p_users,
            "uint32",
            "users",
            "Users with pending jobs on cluster")

    transmit_data("slurm_users_onhold",
            count_distinct_h_users,
            "uint32",
            "users",
            "Users with jobs on hold on cluster")

# MEASUREMENT: Commits historic job history.
def historic_jobs():
    try:
        v = readcmd([SDIAG])
    except ReadCmdException:
        # Try again next time.
        return

    firstrun = 0

    sub   = int(v[7].split()[2])
    start = int(v[8].split()[2])
    comp  = int(v[9].split()[2])
    canc  = int(v[10].split()[2])
    fail  = int(v[11].split()[2])

    transmit_data("slurm_jobs_submitted",
            sub,
            "uint32",
            "jobs/minute",
            "Jobs submitted to slurm since sdiag reset")

    transmit_data("slurm_jobs_started",
            start,
            "uint32",
            "jobs/minute",
            "Jobs started by slurm since sdiag reset")

    transmit_data("slurm_jobs_completed",
            comp,
            "uint32",
            "jobs/minute",
            "Jobs completed through slurm since sdiag reset")

    transmit_data("slurm_jobs_cancelled",
            canc,
            "uint32",
            "jobs/minute",
            "Jobs cancelled on slurm since sdiag reset")

    transmit_data("slurm_jobs_failed",
            fail,
            "uint32",
            "jobs/minute",
            "Jobs failed on slurm since sdiag reset")

# MEASUREMENT: Status of nodes
def node_status():
    try:
        v = readcmd([SINFO, "-h", "-o", "%P %n %T %c"])
    except ReadCmdException:
        # Try again next time.
        return 

    drained   = 0
    allocated = 0
    idle      = 0
    down      = 0
    num_cpus  = 0

    all_keys = ["allocated", "mixed", "draining", "failing", "completing"]
    idl_keys = ["idle"]
    dow_keys = ["down", "fail", "unknown"]
    dra_keys = ["drained"]
    seen_nodes = set()

    for line in v:
        ar = line.split()
        status = ar[2]
        if ar[1] in seen_nodes:
            continue
        seen_nodes.add(ar[1])

        # A '*' is added if the host isn't responding, which is why this looks
        # as it does.
        if any(map(lambda st: status.startswith(st), all_keys)):
            allocated += 1
            num_cpus  += int(ar[3])
        if any(map(lambda st: status.startswith(st), idl_keys)):
            idle += 1
            num_cpus  += int(ar[3])
        if any(map(lambda st: status.startswith(st), dow_keys)):
            down += 1
        if any(map(lambda st: status.startswith(st), dra_keys)):
            drained += 1

    #print "All: {0}, Idle: {1}, Down: {2}, Drain: {3}".format(allocated, idle, down, drained)

    transmit_data("slurm_nodes_allocated",
            allocated,
            "uint32",
            "nodes",
            "Amount of nodes with status allocated")

    transmit_data("slurm_nodes_idle",
            idle,
            "uint32",
            "nodes",
            "Amount of nodes with status idle")

    transmit_data("slurm_nodes_drained",
            drained,
            "uint32",
            "nodes",
            "Amount of nodes with status drained")

    transmit_data("slurm_nodes_down",
            down,
            "uint32",
            "nodes",
            "Amount of nodes with status down")

    transmit_data("slurm_cores_total",
            num_cpus,
            "uint32",
            "cores",
            "Total amount of cores available or idle")

# Find all the users.
def user_overview():
    try:
        v = readcmd([SQUEUE, "--array", "-h", "-o", "%u %t"])
    except ReadCmdException:
        # Try again next time.
        return

    run = {}
    pen = {}
    hol = {}

    for line in v:
        ar = line.split()
        if ar[1] in ["R"]:
            if ar[0] in run:
                run[ar[0]] += 1
            else:
                run[ar[0]] = 1

        elif ar[1] in ["PD"]:
            if ar[0] in d:
                d[ar[0]] += 1
            else:
                d[ar[0]] = 1


# Main event loop.
def ticker(signum, frame):
    historic_jobs()
    node_status()

    data = gather_squeue_data()
    if data != None:
        active_jobs(data)
        waiting_time(data)
        cores_per_user(data)

    #jobstatus = active_jobs()
    # -- temp: sacct is slow right now, don't update this
    # waiting_time(jobstatus) # Waiting time depends on active_jobs being called first.
    #cores_per_user()

def killhandler(signum, frame):
    sys.exit(0)

# Double-fork daemonization
if __name__ == "__main__":
    mypid = os.getpid()

    # This nifty thing kills all other processes that match sys.argv[0]
    # through pgrep.
    os.system("pgrep " + os.path.basename(sys.argv[0]) +
            " | grep -v " + str(mypid) + " | xargs -r -n 1 kill -9")

    if DAEMONIZE:
        try:
            pid = os.fork()
            if pid > 0:
                sys.exit(0)
        except OSError, e:
            print >>sys.stderr, "fork #1 failed: %d (%s)" % (e.errno, e.strerror)
            sys.exit(1)

        os.chdir("/")
        os.setsid()
        os.umask(0)

        try:
            pid = os.fork()
            if pid > 0:
                sys.exit(0)
        except OSError, e:
            print >>sys.stderr, "fork #2 failed: %d (%s)" % (e.errno, e.strerror)


    # Find when we start, we run at second 58 each minute.
    now = time.time()
    init_time = now
    init_time = init_time - (init_time % 60) + 58

    # The timer won't run with 0 init time
    if init_time == now:
        init_time += 1

    ltime = time.localtime(init_time)

    # Set up our timer listener
    signal.signal(signal.SIGALRM, ticker)
    signal.signal(signal.SIGINT, killhandler) 

    if not ONESHOT:
        # Start the timer
        signal.setitimer(signal.ITIMER_REAL, init_time - now, 60)
        #signal.setitimer(signal.ITIMER_REAL, 3, 5)
    else:
        ticker(0, 0)
        sys.exit(0)

    while 1:
        # Pause until we get a signal, then pause again.
        signal.pause()
